{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Building Blocks of Neural Networks\n",
    "\n",
    "Let's look at a concrete example of a neural network.\n",
    "\n",
    "## The MNIST Dataset\n",
    "\n",
    "The problem we are trying to solve here is to classify grayscale images of handwritten digits (28 x 28 pixels) into their 10 categories (0 through 9). The MNIST consists of 60,000 training images, plus 10,000 test images. \n",
    "\n",
    "We start by loading the MNIST dataset in Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the MNIST dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_images and train_labels from the training set, the data that the model will learn from. The model will then be tested on the test set, `test_images` and `test_labels`. The images are encoded as Numpy arrays, and the labels are an array of digits, ranging from 0 to 9.  \n",
    "\n",
    "Let's look at one of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb8a6baa890>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(train_images[0], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, all current machine learning systems use tensors as their basic data structure. Tensors are containers of data. They are a generalization of matrices to an arbitrary number of dimensions. A matrix is actually a rank-2 tensor. In the context of tensors, a dimension is often called an axis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the number of axes of the tensor\n",
    "train_images.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is the shape\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data type:\n",
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we have here is a rank-3 tensor of 8-bit integers. More precisely, it’s an array of 60,000 matrices of 28 × 28 integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow will be as follows: First, we'll feed the neural network the training data, `train_images` and `train_labels`. The network will then learn to associate images and labels.  Finally, we’ll ask the network to produce predictions for `test_images`, and we’ll verify whether these predictions match the labels from `test_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 15:27:07.274149: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# The network architecture\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using TensorFlow, you define your layers using `Sequential`. Inside the `Sequential`, you then specify what each layer looks like. The core building block of neural networks is the layer. Each layer extract some representations out of the data fed into it. Most of deep learning consists of chaining together simple layers that will implement a form of progressive *data distillation*.  \n",
    "Here, our model consists of a sequence of two *Dense* layers. `Dense` means a set of fully connected neurons.  \n",
    "\n",
    "To make the model ready for training, we need to pick three more things as part of the compilation step:\n",
    "\n",
    "* An optimizer\n",
    "* A loss function\n",
    "* Metrics to monitor during training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The compilation step\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, we'll process the data by reshaping it into the shape the model expects and scaling it so that all values are in the [0, 1] interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the image data\n",
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype('float32')/255\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images =test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train the model, which in Keras is done via a call to the model's `fit()` method -- we fit the model to its training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.2541 - accuracy: 0.9255\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.1041 - accuracy: 0.9692\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0687 - accuracy: 0.9794\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0506 - accuracy: 0.9845\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0380 - accuracy: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8a6e59ea0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two quantities are displayed during training: the loss of the model over the training data, and the accuracy of the model over the training data.  We quickly reach an accuracy of 98.9\\% on the training data.   \n",
    "\n",
    "Now that we have a trained model, we can use it to predict class probabilities for new digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.2309120e-08, 8.1238116e-10, 2.7267752e-05, 1.5365715e-04,\n",
       "       3.3946516e-13, 1.1425795e-07, 7.4341961e-14, 9.9981862e-01,\n",
       "       1.8723216e-07, 1.7418469e-07], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "test_digits = test_images[0:10]\n",
    "predictions = model.predict(test_digits)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each number of index `i` in that array corresponds to the probability that digit image `test_digits[0]` belongs to class `i`.  \n",
    "This first test digit has the highest probability score (almost 1) at index 7: So according to our model, it must be a 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998186"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using argmax() to get the index with the max probability\n",
    "predictions[0].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that it matches the test label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see, on average, how good is our model at classifying new digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0636 - accuracy: 0.9807\n",
      "test-set accuracy = 0.9807000160217285\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on new data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"test-set accuracy = {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test-set accuracy turns out to be 98\\%, which is a bit lower than the training-set accuracy. This gap between training accuracy and test accuracy is an example of overfitting: The fact that machine learning models tend to perform worse on new data than on their training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST\n",
    "\n",
    "In the last section we've seen how to build and train a neural network to classify handwritten digits in less than 15 lines of Python code. Let's try the same code on another dataset: the fanion MNIST. The data set has the same number of records, the same image dimensions and the same number of classes as the dataset from above. So let's \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = data.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb8bfcc19f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[0], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try another optimizer:\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2570 - accuracy: 0.9057\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2439 - accuracy: 0.9101\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2305 - accuracy: 0.9147\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2253 - accuracy: 0.9169\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2182 - accuracy: 0.9176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb868fb7c40>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4709866e-08, 8.1350004e-17, 8.3219985e-12, 1.3239440e-12,\n",
       "       3.5923241e-12, 4.5991055e-05, 1.1983514e-08, 2.8292860e-03,\n",
       "       1.0218864e-09, 9.9712473e-01], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "test_fashion = test_images[0:10]\n",
    "predictions = model.predict(test_fashion)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using argmax() to get the index with the max probability\n",
    "predictions[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3364 - accuracy: 0.8843\n",
      "test-set accuracy = 0.8842999935150146\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on new data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"test-set accuracy = {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4582bebe57ac5e03678c10a89eb99ce45d69bfa9638c2308efce0b4b8482c54a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 ('fintech')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
